{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xxu7h8e4Cm9u",
        "outputId": "765f10f0-10a7-4d65-f17c-9803be353388"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchdata==0.4.1\n",
            "  Downloading torchdata-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.4.1) (2.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata==0.4.1) (2.32.3)\n",
            "Collecting portalocker>=2.0.0 (from torchdata==0.4.1)\n",
            "  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting torch==1.12.1 (from torchdata==0.4.1)\n",
            "  Downloading torch-1.12.1-cp310-cp310-manylinux1_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.12.1->torchdata==0.4.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.4.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.4.1) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.4.1) (2024.8.30)\n",
            "Downloading torchdata-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-1.12.1-cp310-cp310-manylinux1_x86_64.whl (776.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: torch, portalocker, torchdata\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "peft 0.13.2 requires torch>=1.13.0, but you have torch 1.12.1 which is incompatible.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 1.12.1 which is incompatible.\n",
            "torchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 1.12.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed portalocker-3.0.0 torch-1.12.1 torchdata-0.4.1\n",
            "Collecting transformers==4.22.2\n",
            "  Downloading transformers-4.22.2-py3-none-any.whl.metadata (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2) (0.26.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2) (2.32.3)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1 (from transformers==4.22.2)\n",
            "  Downloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers==4.22.2) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers==4.22.2) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.22.2) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.22.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.22.2) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.22.2) (2024.8.30)\n",
            "Downloading transformers-4.22.2-py3-none-any.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.20.3\n",
            "    Uninstalling tokenizers-0.20.3:\n",
            "      Successfully uninstalled tokenizers-0.20.3\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.46.3\n",
            "    Uninstalling transformers-4.46.3:\n",
            "      Successfully uninstalled transformers-4.46.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "peft 0.13.2 requires torch>=1.13.0, but you have torch 1.12.1 which is incompatible.\n",
            "sentence-transformers 3.2.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.22.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tokenizers-0.12.1 transformers-4.22.2\n",
            "Collecting torchvision==0.13.1\n",
            "  Downloading torchvision-0.13.1-cp310-cp310-manylinux1_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torchvision==0.13.1) (4.12.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.13.1) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.13.1) (2.32.3)\n",
            "Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.13.1) (1.12.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.13.1) (11.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.13.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.13.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.13.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.13.1) (2024.8.30)\n",
            "Downloading torchvision-0.13.1-cp310-cp310-manylinux1_x86_64.whl (19.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchvision\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu121\n",
            "    Uninstalling torchvision-0.20.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu121\n",
            "Successfully installed torchvision-0.13.1\n",
            "Collecting torchtext==0.13.1\n",
            "  Downloading torchtext-0.13.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.13.1) (4.66.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.13.1) (2.32.3)\n",
            "Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.10/dist-packages (from torchtext==0.13.1) (1.12.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.13.1) (1.26.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.12.1->torchtext==0.13.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.13.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.13.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.13.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.13.1) (2024.8.30)\n",
            "Downloading torchtext-0.13.1-cp310-cp310-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchtext\n",
            "Successfully installed torchtext-0.13.1\n",
            "Collecting torchaudio==0.12.1\n",
            "  Downloading torchaudio-0.12.1-cp310-cp310-manylinux1_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.10/dist-packages (from torchaudio==0.12.1) (1.12.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.12.1->torchaudio==0.12.1) (4.12.2)\n",
            "Downloading torchaudio-0.12.1-cp310-cp310-manylinux1_x86_64.whl (3.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchaudio\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.5.1+cu121\n",
            "    Uninstalling torchaudio-2.5.1+cu121:\n",
            "      Successfully uninstalled torchaudio-2.5.1+cu121\n",
            "Successfully installed torchaudio-0.12.1\n"
          ]
        }
      ],
      "source": [
        "# Install miscellaneous libraries.\n",
        "!pip install torchdata==0.4.1\n",
        "!pip install transformers==4.22.2\n",
        "!pip install torchvision==0.13.1\n",
        "!pip install torchtext==0.13.1\n",
        "!pip install torchaudio==0.12.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5fQf34J3cJY-"
      },
      "outputs": [],
      "source": [
        "# Import libraries used throughout - if you need other libraries,\n",
        "# you are free to import them.\n",
        "import functools\n",
        "import random\n",
        "import gc\n",
        "from typing import Any\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchtext\n",
        "import torchtext.functional as F\n",
        "import torchtext.transforms\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchtext.datasets import UDPOS\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from transformers import BertModel, BertTokenizer\n",
        "from queue import PriorityQueue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "F4OW-ryOCwbG"
      },
      "outputs": [],
      "source": [
        "# Constants and hyperparameters - you are free to change these for\n",
        "# the bonus question.\n",
        "SEED = 42\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 3\n",
        "LR = 2e-5\n",
        "DEVICE = \"cuda\"\n",
        "TRANSFORMER = \"bert-base-uncased\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lYinc-SdCzdZ"
      },
      "outputs": [],
      "source": [
        "# Reproducibility.\n",
        "torch.manual_seed(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.use_deterministic_algorithms(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272,
          "referenced_widgets": [
            "498f457fbcc14886875fab4fcd871f59",
            "1060efb83b8d476c8d9e72b7f9ee5827",
            "6d2222cb877b4bf28ddee618c3eeac6d",
            "148d87bc17934e8ba2b322ad4a3280b8",
            "26598c6c02334282a02356f958672802",
            "779010892eef4adba5c765ec22ae3384",
            "10a706b2df004e259887993843ce3bad",
            "6bbcc8c442b343edb59c3a16eb144b14",
            "ca27d7d7815747fe8127e5568510c6a0",
            "6f0d7278e9364215963e096127450f13",
            "b8160921d3034fc8b9b30dffdbe38e37",
            "febb608d89a5419bbc70774c234e2aae",
            "5e08f668f065483e84e52b1ea532aec6",
            "5b1a46a3cc84494d83ca509e414028a9",
            "4fb3fe063a6045a88a17727c6ff96ac1",
            "ffc8a590e3e74589ba0c27c51fdc4343",
            "8df17a5aeb9d4eb9ac3144745f85106a",
            "e82297e88da0405db434e7786864cd10",
            "a756d639d44d4c2ba12c093d3ee7b99f",
            "738f7c9e49124a88a1d5febf1c84ed91",
            "e616948a07754177bf50292ac8282d45",
            "121f62a69e694b11b109f0ce322f13d5",
            "26a3355998a64550af04777458f8fdf0",
            "89ca8d90839244669e8aa735c7bff21a",
            "d6b5166b421a449f862203a26811008c",
            "fdc38209c0f9464295d2399f3b19248d",
            "a854370ead25404bb74e4ce4975871c6",
            "73c174c01a6d451e88e803fd447ece4b",
            "8585a41acf78491493ed95c5363e35e9",
            "7c6965d1559d4ef997d800a542fe98a8",
            "be6fe02046d046b1bebbc12f20f744e0",
            "284a2cb092454bb2be87f530a1a2c5d2",
            "aef28ee514ab4aaa811fd9155a06fa37"
          ]
        },
        "id": "YrTZG0UHC1YU",
        "outputId": "31bad3e4-02e8-4b6c-d6f7-edb2b0ab1ad2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "498f457fbcc14886875fab4fcd871f59"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "febb608d89a5419bbc70774c234e2aae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26a3355998a64550af04777458f8fdf0"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Setting up dataloaders for training.\n",
        "tokenizer = BertTokenizer.from_pretrained(TRANSFORMER)\n",
        "init_token = tokenizer.cls_token\n",
        "pad_token = tokenizer.pad_token\n",
        "init_token_idx = tokenizer.convert_tokens_to_ids(init_token)\n",
        "pad_token_idx = tokenizer.convert_tokens_to_ids(pad_token)\n",
        "max_input_length = tokenizer.max_model_input_sizes[TRANSFORMER]\n",
        "\n",
        "train_datapipe = UDPOS(split=\"train\")\n",
        "valid_datapipe = UDPOS(split=\"valid\")\n",
        "pos_vocab = build_vocab_from_iterator(\n",
        "    [i[1] for i in list(train_datapipe)],\n",
        "    specials=[init_token, pad_token],\n",
        ")\n",
        "\n",
        "\n",
        "def prepare_words(tokens, tokenizer, max_input_length):\n",
        "    \"\"\"Preprocesses words such that they may be passed into BERT.\n",
        "\n",
        "    Parameters\n",
        "    ---\n",
        "    tokens : List\n",
        "        List of strings, each of which corresponds to one token in a sequence.\n",
        "    tokenizer : transformers.models.bert.tokenization_bert.BertTokenizer\n",
        "        Tokenizer to be used for transforming word strings into word indices\n",
        "        to be used with BERT.\n",
        "    max_input_length : int\n",
        "        Maximum input length of each sequence as expected by our version of BERT.\n",
        "    Returns\n",
        "    ---\n",
        "    tokens : List\n",
        "        List of preprocessed tokens.\n",
        "    \"\"\"\n",
        "    # Append beginning of sentence and end of sentence markers\n",
        "    # lowercase each token and cut them to the maximum length\n",
        "    # (minus two to account for beginning and end of sentence).\n",
        "    tokens = (\n",
        "        [i.lower() for i in tokens[: max_input_length]]\n",
        "    )\n",
        "    # Convert word strings to indices.\n",
        "    tokens = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    return tokens\n",
        "\n",
        "\n",
        "def prepare_tags(tokens, max_input_length):\n",
        "    \"\"\"Convert tag strings into indices for use with torch. For symmetry, we perform\n",
        "        identical preprocessing as on our words, even though we do not need beginning\n",
        "        of sentence and end of sentence markers for our tags.\n",
        "\n",
        "    Parameters\n",
        "    ---\n",
        "    tokens : List\n",
        "        List of strings, each of which corresponds to one token in a sequence.\n",
        "    max_input_length : int\n",
        "        Maximum input length of each sequence as expected by our version of BERT.\n",
        "    Returns\n",
        "    ---\n",
        "    tokens : List\n",
        "        List of preprocessed tags.\n",
        "    \"\"\"\n",
        "    # Append beginning of sentence and end of sentence markers\n",
        "    # cut the tagging sequence to the maximum length (minus two to account for beginning and end of sentence).\n",
        "    tokens = tokens[: max_input_length]\n",
        "    # Convert tag strings to indices.\n",
        "    tokens = torchtext.transforms.VocabTransform(pos_vocab)(tokens)\n",
        "    return tokens\n",
        "\n",
        "\n",
        "text_preprocessor = functools.partial(\n",
        "    prepare_words,\n",
        "    tokenizer=tokenizer,\n",
        "    max_input_length=max_input_length,\n",
        ")\n",
        "\n",
        "tag_preprocessor = functools.partial(\n",
        "    prepare_tags,\n",
        "    max_input_length=max_input_length,\n",
        ")\n",
        "\n",
        "\n",
        "def apply_transform(x):\n",
        "    return text_preprocessor(x[0]), tag_preprocessor(x[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ikF2VKvqC2DS"
      },
      "outputs": [],
      "source": [
        "train_datapipe = (\n",
        "    train_datapipe.map(apply_transform)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .rows2columnar([\"words\", \"pos\"])\n",
        ")\n",
        "train_dataloader = DataLoader(train_datapipe, batch_size=None, shuffle=False)\n",
        "valid_datapipe = (\n",
        "    valid_datapipe.map(apply_transform)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .rows2columnar([\"words\", \"pos\"])\n",
        ")\n",
        "valid_dataloader = DataLoader(valid_datapipe, batch_size=None, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8AgCIq_AC7K5"
      },
      "outputs": [],
      "source": [
        "class TagLSTM(nn.Module):\n",
        "    \"\"\"Models an LSTM on top of a transformer to predict POS in a Neural CRF.\"\"\"\n",
        "\n",
        "    def __init__(self, nb_labels, emb_dim, hidden_dim=256):\n",
        "        \"\"\"Constructor.\n",
        "\n",
        "        Parameters\n",
        "        ---\n",
        "        nb_labels : int\n",
        "            Number of POS tags to be considered.\n",
        "\n",
        "        emb_dim : int\n",
        "            Input_size of the LSTM - effectively embedding dimension of our pretrained transformer.\n",
        "\n",
        "        hidden_dim : int\n",
        "            Hidden dimension of the LSTM.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.lstm = nn.LSTM(\n",
        "            emb_dim, hidden_dim // 2, bidirectional=True, batch_first=True\n",
        "        )\n",
        "        self.tag = nn.Linear(hidden_dim, nb_labels).to(DEVICE)\n",
        "        self.hidden = None\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        return (\n",
        "            torch.randn(2, batch_size, self.hidden_dim // 2).to(DEVICE),\n",
        "            torch.randn(2, batch_size, self.hidden_dim // 2).to(DEVICE),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.hidden = self.init_hidden(x.shape[0])\n",
        "        x, self.hidden = self.lstm(x, self.hidden)\n",
        "        x = self.tag(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class NeuralCRF(nn.Module):\n",
        "    \"\"\"Class modeling a neural CRF for POS tagging.\n",
        "    We model tag-tag dependencies with a weight for each transition\n",
        "    and word-tag influence through an LSTM on top of a pretrained transformer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        pad_idx_word,\n",
        "        pad_idx_pos,\n",
        "        bot_idx,\n",
        "        t_cal,\n",
        "        transformer,\n",
        "        lstm_hidden_dim=64,\n",
        "        beta=0,\n",
        "    ):\n",
        "        \"\"\"Constructor.\n",
        "\n",
        "        Parameters\n",
        "        ---\n",
        "        pad_idx_word : int\n",
        "            Index corresponding to padding in the word sequences.\n",
        "        pad_idx_pos : int\n",
        "            Index corresponding to padding in the tag sequences.\n",
        "        bot_idx : int\n",
        "            Index corresponding to beginning of tag marker in the tag sequences.\n",
        "        t_cal : List[int]\n",
        "            List containing all indices corresponding to tags in the tag sequences.\n",
        "        transformer : BertModel\n",
        "            Pretrained transformer used to embed sentences before feeding them\n",
        "            into the LSTM.\n",
        "        lstm_hiden_dim : int\n",
        "            Hidden dimension of the LSTM used for POS tagging. Note that\n",
        "            since we are bidirectional, the effective hidden dimension\n",
        "            is half of this number.\n",
        "        beta : float\n",
        "            Regularization hyperparameter of the entropy regularizer.\n",
        "            Entropy regularization is only applied for \\beta > 0.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.pad_idx_word = pad_idx_word\n",
        "        self.pad_idx_pos = pad_idx_pos\n",
        "        self.bot_idx = bot_idx\n",
        "        self.t_cal = t_cal\n",
        "        self.transformer = transformer\n",
        "        self.lstm_hidden_dim = lstm_hidden_dim\n",
        "        self.beta = beta\n",
        "        self.transitions = nn.Parameter(torch.empty(len(t_cal), len(t_cal))).to(DEVICE)\n",
        "        self.emissions = TagLSTM(\n",
        "            len(t_cal),\n",
        "            transformer.config.to_dict()[\"hidden_size\"],\n",
        "            lstm_hidden_dim,\n",
        "        ).to(DEVICE)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        nn.init.uniform_(self.transitions, -0.1, 0.1)\n",
        "\n",
        "    def forward(self, W):\n",
        "        \"\"\"Decode each sentence within W and return predicted tagging.\n",
        "\n",
        "        Parameters\n",
        "        ---\n",
        "        W : torch.tensor\n",
        "            Word sequences of dimension batch size x max sentence length within batch.\n",
        "\n",
        "        Returns\n",
        "        ---\n",
        "        sequences : list\n",
        "            List of tensors, each of which contains the predicted tag indices for a particular\n",
        "            word sequence.\n",
        "        \"\"\"\n",
        "        # Calculate scores.\n",
        "        emissions = self.calculate_emissions(W)\n",
        "        # Run viterbi sentence by sentence.\n",
        "        sequences = []\n",
        "        for sentence in range(W.shape[0]):\n",
        "            # Exclude beginning and end markers from each word sequence.\n",
        "            scores, backpointers = self.backward_viterbi_log(\n",
        "                W[sentence, ], emissions[sentence, :]\n",
        "            )\n",
        "            sequences += [self.get_viterbi(backpointers)]\n",
        "        return sequences\n",
        "\n",
        "    def calculate_emissions(self, W):\n",
        "        \"\"\"Calculate emissions (i.e., scores for each word and batch).\n",
        "\n",
        "        Parameters\n",
        "        ---\n",
        "        W : torch.tensor\n",
        "            Word sequences of dimension batch size x max sentence\n",
        "            length within batch.\n",
        "\n",
        "        Returns\n",
        "        ---\n",
        "        emissions : torch.tensor\n",
        "            Word level scores for each tag of dimension batch_size x max\n",
        "            sentence length within batch x |T|.\n",
        "        \"\"\"\n",
        "        return self.emissions(self.transformer(W)[0])\n",
        "\n",
        "    def loss(self, T, W):\n",
        "        \"\"\"Calculate the loss for a batch.\n",
        "\n",
        "        Parameters\n",
        "        ---\n",
        "        T : torch.tensor\n",
        "            True taggings for each sequence within the batch.\n",
        "            Of dimension batch size x longest sequence within batch.\n",
        "            Note the paddings, have been added to T for symmetry.\n",
        "        W : torch.tensor\n",
        "            Words for each sequence within the batch.\n",
        "            Of dimension batch size x longest sequence within batch.\n",
        "            Note that paddings have been added to W.\n",
        "\n",
        "        Returns\n",
        "        ---\n",
        "        torch.tensor\n",
        "            Mean loss for the batch.\n",
        "        \"\"\"\n",
        "        emissions = self.calculate_emissions(W)\n",
        "        scores = self.score(emissions, W, T)\n",
        "        log_normalizer = self.backward_log_Z(W, emissions)\n",
        "\n",
        "        loss = torch.negative(torch.mean(scores - log_normalizer))\n",
        "        if self.beta > 0.0:\n",
        "            unnormalized_entropy = self.backward_entropy(\n",
        "                W, emissions\n",
        "            )\n",
        "            entropy = (\n",
        "                (unnormalized_entropy / torch.exp(log_normalizer))\n",
        "                + log_normalizer\n",
        "            )\n",
        "            if torch.isinf(torch.max(torch.exp(log_normalizer))):\n",
        "                return loss\n",
        "            else:\n",
        "                return loss + torch.negative(self.beta * torch.mean(entropy))\n",
        "        else:\n",
        "            return loss\n",
        "\n",
        "    def score(self, emissions, W, T):\n",
        "        \"\"\"Calculate scores for specified taggings and word sequences.\n",
        "\n",
        "        Parameters\n",
        "        ---\n",
        "        emissions : torch.tensor\n",
        "        T : torch.tensor\n",
        "            Taggings for each sequence within the batch.\n",
        "            Of dimension batch size x longest sequence within batch.\n",
        "            Note the paddings have been added to T.\n",
        "            We expect T to already have the initial BOT tag indices removed\n",
        "            (see `loss` for details).\n",
        "        W : torch.tensor\n",
        "            Words for each sequence within the batch.\n",
        "            Of dimension batch size x longest sequence within batch.\n",
        "            Note the paddings have been added to W so we mask them out here.\n",
        "            (see `loss` for details).\n",
        "\n",
        "        Returns\n",
        "        ---\n",
        "        scores : torch.tensor\n",
        "            score(T, W) for all samples in W.\n",
        "        \"\"\"\n",
        "        scores = (\n",
        "            emissions[:, 0].gather(1, (T[:, 0]).unsqueeze(1)).squeeze()\n",
        "            + self.transitions[self.bot_idx, T[:, 0]]\n",
        "        )\n",
        "        for word in range(1, emissions.shape[1]):\n",
        "            mask = torch.where(\n",
        "                W[:, word] == self.pad_idx_word, 0, 1\n",
        "            )\n",
        "            scores += mask * (\n",
        "                emissions[:, word]\n",
        "                .gather(1, (T[:, word]).unsqueeze(1))\n",
        "                .squeeze()\n",
        "                + self.transitions[T[:, word - 1], T[:, word]]\n",
        "            )\n",
        "        return scores\n",
        "\n",
        "    def viterbi_naive(self, W, emissions):\n",
        "        \"\"\"Calculate best tagging naively and return both the best score and best tagging in log space.\n",
        "\n",
        "        NB: This naive version is not vectorized over samples.\n",
        "\n",
        "        Parameters\n",
        "        ---\n",
        "        W : torch.tensor\n",
        "            Of dimension longest sequence within batch or less.\n",
        "            Note the paddings have been added to W so we manually remove them here if present.\n",
        "        emissions : torch.tensor\n",
        "            Word level scores for each tag of dimension max\n",
        "            sentence length within batch x |T|\n",
        "\n",
        "        Returns\n",
        "        ---\n",
        "        Tuple[torch.tensor, torch.tensor]\n",
        "            Tuple containing the log-score of the best tagging and the\n",
        "            indices of the best tagging for W.\n",
        "        \"\"\"\n",
        "        T = self.t_cal\n",
        "        # Remove padding.\n",
        "        if torch.any(W == self.pad_idx_word):\n",
        "            W = W[torch.where(W != self.pad_idx_word)[0]]\n",
        "        T_abs = len(T)\n",
        "        combinations = torch.combinations(\n",
        "            T, r=W.shape[0], with_replacement=True\n",
        "        ).to(DEVICE)\n",
        "        combinations = torch.cartesian_prod(*[T for ix in range(W.shape[0])]).to(DEVICE)\n",
        "        best_score = torch.tensor(0.0, dtype=torch.float64).to(DEVICE)\n",
        "        best_tag = torch.tensor([]).to(DEVICE)\n",
        "        for ix, combination in enumerate(combinations):\n",
        "            if W.shape[0] == 1:\n",
        "                current_score = (\n",
        "                    emissions[0, combination]\n",
        "                    + self.transitions[self.bot_idx, combination]\n",
        "                )\n",
        "            else:\n",
        "                current_score = (\n",
        "                    emissions[0, combination[0]]\n",
        "                    + self.transitions[self.bot_idx, combination[0]]\n",
        "                )\n",
        "                for qx in range(1, combination.shape[0]):\n",
        "                    current_score += (\n",
        "                        emissions[qx, combination[qx]]\n",
        "                        + self.transitions[\n",
        "                            combination[qx - 1], combination[qx]\n",
        "                        ]\n",
        "                    )\n",
        "\n",
        "            if (current_score) > best_score:\n",
        "                best_score = current_score.double()\n",
        "                best_tag = combination\n",
        "        return best_score, best_tag\n",
        "\n",
        "    def log_Z_naive(self, W, emissions):\n",
        "        \"\"\"Calculate log Z naively.\n",
        "\n",
        "        NB: This naive version is not vectorized over samples.\n",
        "\n",
        "        Parameters\n",
        "        ---\n",
        "        W : torch.tensor\n",
        "            Of dimension longest sequence within batch or less.\n",
        "            Note the paddings have been added to W so we manually remove them here if present.\n",
        "        emissions : torch.tensor\n",
        "            Word level scores for each tag of dimension max\n",
        "            sentence length within batch x |T|\n",
        "\n",
        "        Returns\n",
        "        ---\n",
        "        torch.tensor\n",
        "            Log Z for W.\n",
        "        \"\"\"\n",
        "        T = self.t_cal\n",
        "        # Remove padding\n",
        "        W = W[torch.where(W != self.pad_idx_word)[0]]\n",
        "        T_abs = len(T)\n",
        "\n",
        "        # Generate \\mathcal{T}^N.\n",
        "        combinations = torch.cartesian_prod(*[T for ix in range(W.shape[0])]).to(DEVICE)\n",
        "        log_normalizer = torch.zeros(\n",
        "            combinations.shape[0], dtype=torch.float64\n",
        "        ).to(DEVICE)\n",
        "        # Loop over all possible combinations naively.\n",
        "        # NB: This is essentially line one on Slide 50.\n",
        "        for ix, combination in enumerate(combinations):\n",
        "            # Kludge since indexing is slightly different for one-dim\n",
        "            # tensors vs two tensors.\n",
        "            if W.shape[0] == 1:\n",
        "                # Calculate score as the sum of emissions (i.e., how well\n",
        "                # does a word match a tag based on BERT embeddings) and\n",
        "                # transitions (globally, how likely is a transition\n",
        "                # from the previous tag to the current tag).\n",
        "                # NB: For the first word, the initial tag is always BOT.\n",
        "                # NB 2: Since we are in log-space, the exp\n",
        "                # of the score goes away.\n",
        "                log_normalizer[ix] = (\n",
        "                    emissions[0, combination]\n",
        "                    + self.transitions[self.bot_idx, combination]\n",
        "                )\n",
        "\n",
        "            else:\n",
        "                # Initial score is identical to above.\n",
        "                log_normalizer[ix] = (\n",
        "                    emissions[0, combination[0]]\n",
        "                    + self.transitions[self.bot_idx, combination[0]]\n",
        "                )\n",
        "                for qx in range(1, combination.shape[0]):\n",
        "                    # Score within each potential tagging\n",
        "                    # is calculated the same as above except that we now\n",
        "                    # actually use the previous tag instead of always\n",
        "                    # BOT.\n",
        "                    log_normalizer[ix] += (\n",
        "                        emissions[qx, combination[qx]]\n",
        "                        + self.transitions[\n",
        "                            combination[qx - 1], combination[qx]\n",
        "                        ]\n",
        "                    )\n",
        "        # Calculate logsumexp numerically stable\n",
        "        # since we are in log-space.\n",
        "        return torch.logsumexp(log_normalizer, 0)\n",
        "\n",
        "\n",
        "    def entropy_naive(self, W, emissions):\n",
        "        \"\"\"Calculate the unnormalized entropy naively.\n",
        "\n",
        "        NB: This naive version is not vectorized over samples.\n",
        "\n",
        "        Parameters\n",
        "        ---\n",
        "        W : torch.tensor\n",
        "            Words for each sequence within the batch.\n",
        "            Of dimension longest sequence within batch or less.\n",
        "            Note the paddings have been added to W so we manually remove them here if present.\n",
        "        emissions : torch.tensor\n",
        "            Word level scores for each tag of dimension max\n",
        "            sentence length within batch x |T|\n",
        "\n",
        "        Returns\n",
        "        ---\n",
        "        torch.tensor\n",
        "            Log Z for W.\n",
        "        \"\"\"\n",
        "        T = self.t_cal\n",
        "        # Remove padding\n",
        "        W = W[torch.where(W != self.pad_idx_word)[0]]\n",
        "        T_abs = len(T)\n",
        "        combinations = torch.combinations(\n",
        "            T, r=W.shape[0], with_replacement=True\n",
        "        )\n",
        "        combinations = torch.cartesian_prod(T, T)\n",
        "        combinations = torch.cartesian_prod(*[T for ix in range(W.shape[0])]).to(DEVICE)\n",
        "        entropy = torch.zeros(1, dtype=torch.float64).to(DEVICE)\n",
        "        for ix, combination in enumerate(combinations):\n",
        "            if W.shape[0] == 1:\n",
        "                entropy -= torch.exp((\n",
        "                    emissions[0, combination]\n",
        "                    + self.transitions[self.bot_idx, combination]\n",
        "                )) * (\n",
        "                    emissions[0, combination]\n",
        "                    + self.transitions[self.bot_idx, combination]\n",
        "                )\n",
        "\n",
        "            else:\n",
        "                local_score = (\n",
        "                    emissions[0, combination[0]]\n",
        "                    + self.transitions[self.bot_idx, combination[0]]\n",
        "                )\n",
        "                for qx in range(1, combination.shape[0]):\n",
        "                    local_score += (\n",
        "                        emissions[qx, combination[qx]]\n",
        "                        + self.transitions[\n",
        "                            combination[qx - 1], combination[qx]\n",
        "                        ]\n",
        "                    )\n",
        "                entropy -= torch.exp(local_score) * local_score\n",
        "        return entropy\n",
        "\n",
        "    def get_viterbi(self, backpointer_matrix):\n",
        "        \"\"\"Return the best tagging based on a backpointer matrix.\n",
        "\n",
        "        Parameters\n",
        "        ---\n",
        "        backpointer_matrix : torch.tensor\n",
        "            Backpointer matrix from Viterbi indicating which\n",
        "            tag is the highest scoring for each element in the sequence.\n",
        "\n",
        "        Returns\n",
        "        ---\n",
        "        torch.tensor\n",
        "            Indices of the best tagging based on `backpointer_matrix`.\n",
        "        \"\"\"\n",
        "        tagging = torch.zeros(backpointer_matrix.shape[1], device = DEVICE)\n",
        "        next_idx = backpointer_matrix[0,0]\n",
        "        tagging[0] = next_idx\n",
        "\n",
        "        for n in range(1, backpointer_matrix.shape[1]):\n",
        "            next_idx = backpointer_matrix[next_idx, n]\n",
        "            tagging[n] = next_idx\n",
        "        return tagging\n",
        "\n",
        "    def backward_log_Z(self, W, emissions):\n",
        "        \"\"\"Calculate log Z using the backward algorithm.\n",
        "\n",
        "        NB: You do need to vectorize this over samples.\n",
        "\n",
        "        Parameters\n",
        "        ---\n",
        "        W : torch.tensor\n",
        "            Words for each sequence within the batch.\n",
        "            Of dimension batch size x longest sequence within batch.\n",
        "            Note the paddings have been added to W so we mask them out here.\n",
        "        emissions : torch.tensor\n",
        "            Word level scores for each tag of dimension batch_size x max\n",
        "            sentence length within batch x |T|\n",
        "\n",
        "        Returns\n",
        "        ---\n",
        "        torch.tensor\n",
        "            Log Z for each sample in W.\n",
        "        \"\"\"\n",
        "        T = self.t_cal\n",
        "        batch_size, max_seq_len = W.shape\n",
        "        num_tags = len(T)\n",
        "\n",
        "        #mask = torch.where((W!=self.pad_idx_word) & (W!=))\n",
        "\n",
        "        # Obtain the sequence lengths for each seq in batch\n",
        "        lengths = torch.sum(W != self.pad_idx_word, dim=1)\n",
        "        # Mask -> 1 for valid positions, 0 for padding\n",
        "        mask = torch.arange(max_seq_len, device=W.device).expand(batch_size, max_seq_len) < lengths.unsqueeze(1)\n",
        "        mask = mask.long()\n",
        "\n",
        "        # Init beta : t = N-1\n",
        "        #beta = torch.full((batch_size, num_tags), float('-inf'), dtype=torch.float64).to(DEVICE)\n",
        "        beta = torch.zeros((batch_size, num_tags), dtype=torch.float64).to(DEVICE)\n",
        "\n",
        "\n",
        "        # for i in range(batch_size):\n",
        "        #   seq_len = lengths[i].item()\n",
        "        #   if seq_len > 0:\n",
        "        #     beta[i, :] = emissions[i, seq_len-1, :]\n",
        "\n",
        "        # Recursively compute beta from t_{N-1} to t0\n",
        "        for n in range(max_seq_len-2, -1, -1):\n",
        "          valid_mask = mask[:, n+1].unsqueeze(1)\n",
        "          invalid_mask = 1-valid_mask\n",
        "          beta_next = emissions[:, n+1, :] + beta\n",
        "          beta = (torch.logsumexp(self.transitions.unsqueeze(0) + beta_next.unsqueeze(1), dim=2)*valid_mask + beta*invalid_mask)\n",
        "\n",
        "        # Compute initial scores (BOS)\n",
        "        initial_scores = self.transitions[self.bot_idx, :].unsqueeze(0) + emissions[:, 0, :]\n",
        "        log_z = torch.logsumexp(beta + initial_scores, dim=1)\n",
        "        return log_z\n",
        "\n",
        "\n",
        "    def forward_log_Z(self, W, emissions):\n",
        "        \"\"\"Calculate log Z using the forward algorithm.\n",
        "\n",
        "        NB: You do need to vectorize this over samples.\n",
        "\n",
        "        Parameters\n",
        "        ---\n",
        "        W : torch.tensor\n",
        "            Words for each sequence within the batch.\n",
        "            Of dimension batch size x longest sequence within batch.\n",
        "            Note the paddings have been added to W so we mask them out here.\n",
        "        emissions : torch.tensor\n",
        "            Word level scores for each tag of dimension batch_size x max\n",
        "            sentence length within batch x |T|\n",
        "\n",
        "        Returns\n",
        "        ---\n",
        "        torch.tensor\n",
        "            Log Z for each sample in W.\n",
        "        \"\"\"\n",
        "        T = self.t_cal\n",
        "        batch_size, max_seq_len = W.shape\n",
        "        num_tags = len(T)\n",
        "\n",
        "        lengths = torch.sum(W!=self.pad_idx_word, dim=1)\n",
        "\n",
        "        mask = torch.where(W != self.pad_idx_word, 1, 0)\n",
        "        # mask = torch.arange(max_seq_len, device=W.device).expand(batch_size, max_seq_len) < lengths.unsqueeze(1)\n",
        "        # mask = mask.long()\n",
        "\n",
        "        # Init for BOS\n",
        "        alpha = torch.zeros(batch_size, num_tags, dtype=torch.float64, device=W.device) \\\n",
        "            + self.transitions[0, :].unsqueeze(0) \\\n",
        "            + emissions[:, 0, :]\n",
        "        # Recursion\n",
        "        for n in range(1, max_seq_len):\n",
        "        #   valid_mask = mask[:, n].unsqueeze(1)\n",
        "        #   invalid_mask = 1-valid_mask\n",
        "        #   print(type(valid_mask))\n",
        "        #   print(type(invalid_mask))\n",
        "        #   print(type(num_tag))\n",
        "\n",
        "        #   alpha_next = self.transitions.unsqueeze(0) + alpha.unsqueeze(1) + emissions[:, n, :].unsqueeze(1)  # Shape: [batch_size, num_tags, num_tags]\n",
        "        #   alpha = torch.logsumexp(alpha_next, dim=2) * valid_mask + alpha * invalid_mask\n",
        "            alpha_next = (\n",
        "                torch.logsumexp(\n",
        "                    torch.stack(batch_size * [self.transitions]) +\n",
        "                    torch.stack(num_tags * [emissions[:, n, :]], 1) +\n",
        "                    torch.stack(num_tags * [alpha], 2),\n",
        "                    dim=1\n",
        "                )\n",
        "            )\n",
        "            # Apply mask to handle valid/invalid positions\n",
        "            alpha = alpha_next * torch.column_stack(num_tags * [mask[:, n]]) + alpha * torch.column_stack(num_tags * [1 - mask[:, n]])\n",
        "\n",
        "\n",
        "        # Compute log Z\n",
        "        log_z = torch.logsumexp(alpha, dim=1)\n",
        "        return log_z\n",
        "\n",
        "    def backward_entropy(self, W, emissions):\n",
        "        \"\"\"Calculate the unnormalized entropy using the backward algorithm.\n",
        "\n",
        "        NB: You do need to vectorize this over samples.\n",
        "\n",
        "        Parameters\n",
        "        ---\n",
        "        W : torch.tensor\n",
        "            Words for each sequence within the batch.\n",
        "            Of dimension batch size x longest sequence within batch.\n",
        "            Note the paddings have been added to W so we mask them out here.\n",
        "        emissions : torch.tensor\n",
        "            Word level scores for each tag of dimension batch_size x max\n",
        "            sentence length within batch x |T|\n",
        "\n",
        "        Returns\n",
        "        ---\n",
        "        torch.tensor\n",
        "            Unnormalized entropy for each sample in W.\n",
        "        \"\"\"\n",
        "        T = self.t_cal\n",
        "        batch_size, seq_len = W.shape\n",
        "        num_tags = len(T)\n",
        "\n",
        "        # Obtain the sequence lengths for each seq in batch\n",
        "        lengths = torch.sum(W != self.pad_idx_word, dim=1)\n",
        "        # Mask -> 1 for valid positions, 0 for padding\n",
        "        #mask = torch.arange(seq_len, device=W.device).expand(batch_size, seq_len) < lengths.unsqueeze(1)\n",
        "        #mask = mask.long()\n",
        "        mask = torch.where(W != self.pad_idx_word, 1, 0)\n",
        "\n",
        "        b1 = torch.zeros((batch_size, num_tags), dtype=torch.float64, device=DEVICE)\n",
        "        b2 = torch.zeros((batch_size, num_tags), dtype=torch.float64, device=DEVICE)\n",
        "\n",
        "        for n in range(seq_len-2, -1,-1):\n",
        "            valid_mask = mask[:, n+1]\n",
        "            invalid_mask = 1-valid_mask\n",
        "            score = torch.stack(batch_size * [self.transitions]) + \\\n",
        "                    torch.stack(num_tags * [emissions[:, n+1, :]], 1)\n",
        "\n",
        "            b2 = torch.sum(torch.exp(score)*(torch.stack(num_tags*[b2], 1) - score*torch.stack(num_tags*[torch.exp(b1)], 1)),2) * \\\n",
        "                torch.stack(num_tags*[mask[:,n+1]],1) \\\n",
        "                + torch.exp(b1) * torch.stack(num_tags*[1-mask[:,n+1]], 1)\n",
        "\n",
        "            b1 = torch.logsumexp(score + torch.stack(num_tags*[b1], 1), 2) * \\\n",
        "                torch.stack(num_tags*[mask[:,n+1]],1) \\\n",
        "                + b1 * torch.stack(num_tags*[1-mask[:,n+1]], 1)\n",
        "\n",
        "        score_bot = torch.stack(batch_size*[self.transitions[self.bot_idx]]) + emissions[:,0,:]\n",
        "        Hu = torch.sum(torch.exp(score_bot)*(b2-score_bot*torch.exp(b1)),1)\n",
        "        return Hu\n",
        "\n",
        "\n",
        "\n",
        "    def backward_viterbi_log(self, W, emissions):\n",
        "        \"\"\"Calculate the best tagging using the backward algorithm and return\n",
        "            both the scoring matrix in log-space and the backpointer matrix.\n",
        "\n",
        "        NB: You do not need to vectorize this over samples.\n",
        "\n",
        "        Parameters\n",
        "        ---\n",
        "        W : torch.tensor\n",
        "            Of dimension longest sequence within batch or less.\n",
        "            Note the padding have been added to W so we manually remove them here if present.\n",
        "        emissions : torch.tensor\n",
        "            Word level scores for each tag of dimension max\n",
        "            sentence length within batch x |T|\n",
        "\n",
        "        Returns\n",
        "        ---\n",
        "        Tuple[torch.tensor, torch.tensor]\n",
        "            Tuple containing the scoring matrix in log-space and the\n",
        "            backpointer matrix for recovering the best tagging.\n",
        "        \"\"\"\n",
        "        W = W[torch.where(W != self.pad_idx_word)[0]]\n",
        "\n",
        "        T = self.t_cal\n",
        "        seq_len = len(W)\n",
        "        num_tags = len(T)\n",
        "\n",
        "        # BOT\n",
        "        score_bot = self.transitions[self.bot_idx] + emissions[0, :]\n",
        "        # Init scores\n",
        "        scores = torch.zeros((num_tags, seq_len), dtype=torch.float64, device=DEVICE)\n",
        "        # Init backpointer\n",
        "        backpointers = torch.zeros((num_tags, seq_len), dtype=torch.long, device=DEVICE)\n",
        "\n",
        "        # if seq_len == 1:\n",
        "        #     scores[0, :] = self.transitions[self.bot_idx, :] + emissions[0, :]\n",
        "        #     backpointers[0, :] = -1  # No backpointers for a single word\n",
        "        #     return scores, backpointers\n",
        "\n",
        "        # BOT\n",
        "        # scores[:,0] = self.transitions[self.bot_idx, :] + emissions[0,:]\n",
        "\n",
        "        alpha = torch.zeros(num_tags, dtype = torch.float64, device=DEVICE)\n",
        "        scores[:, seq_len-1] = alpha\n",
        "        # Backward Iteration\n",
        "        for n in range(seq_len-2, -1, -1):\n",
        "            alpha = torch.max(self.transitions+emissions[n+1, :]+alpha, 1)\n",
        "            scores[:, n+1] = alpha.values\n",
        "            backpointers[:, n+1] = alpha.indices\n",
        "            alpha = alpha.values\n",
        "            # t = self.transitions.unsqueeze(0)\n",
        "            # e = emissions[n+1,:].unsqueeze(0).expand(num_tags, -1)\n",
        "            # prev_scores = scores[:, n+1].unsqueeze(1)\n",
        "\n",
        "            # total_scores = prev_scores + t + e\n",
        "            # # scores[:, n], backpointers[:, n]\n",
        "            # alpha = torch.max(total_scores, 1)\n",
        "            # # print(alpha.values)\n",
        "            # # print(alpha.indices)\n",
        "            # scores[:, n] = alpha.values\n",
        "            # backpointers[:, n] = alpha.indices\n",
        "            # alpha = alpha.values\n",
        "        alpha, idxs = torch.max(score_bot+alpha, 0)\n",
        "        scores[:, 0] = torch.tensor(num_tags*[alpha])\n",
        "        backpointers[:, 0] = torch.tensor(num_tags*[idxs])\n",
        "        alpha = alpha.values\n",
        "\n",
        "        return scores, backpointers\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def dijkstra_viterbi_log(self, W, emissions):\n",
        "\n",
        "        \"\"\"Calculate the best tagging using Dijsktra's algorithm and return\n",
        "            both the best score and best tagging in log space.\n",
        "\n",
        "        NB: You do not need to vectorize this over samples.\n",
        "\n",
        "        Parameters\n",
        "        ---\n",
        "        W : torch.tensor\n",
        "            Of dimension longest sequence within batch or less.\n",
        "            Note the paddings have been added to W so we manually remove them here if present.\n",
        "        emissions : torch.tensor\n",
        "            Word level scores for each tag of dimension max\n",
        "            sentence length within batch x |T|\n",
        "\n",
        "\n",
        "        Returns\n",
        "        ---\n",
        "        Tuple[torch.tensor, log_Z]\n",
        "            Tuple containing the log-score of the best tagging and log_Z.\n",
        "            NB: We return log_Z if we already use it within the method\n",
        "            to calculate probabilities, such that we don't have to\n",
        "        \"\"\"\n",
        "        W = W[torch.where(W != self.pad_idx_word)[0]]\n",
        "\n",
        "        T = self.t_cal\n",
        "        num_tags = len(T)\n",
        "        seq_len = len(W)\n",
        "\n",
        "        log_z = self.forward_log_Z(W.unsqueeze(0), emissions.unsqueeze(0))\n",
        "\n",
        "        # This implementation return the min over (priority_number, data)\n",
        "        # We gotta append (score, tuple)\n",
        "        # We need to use negative values so this will turn to a max\n",
        "        # https://docs.python.org/3/library/queue.html\n",
        "        queue = PriorityQueue()\n",
        "        popped = set()\n",
        "\n",
        "        gamma = torch.zeros((seq_len+1, num_tags),dtype=torch.float64)\n",
        "\n",
        "        queue.put((0.0, (0, self.bot_idx))) # push <<0mbot>,1> to queue\n",
        "        while not queue.empty():\n",
        "            score, tuple_n_t = queue.get()\n",
        "            n, t = tuple_n_t\n",
        "            popped.add(tuple_n_t)\n",
        "            gamma[n, t] = -score\n",
        "\n",
        "            if n == seq_len:\n",
        "                break\n",
        "            for tag in T:\n",
        "                if (n+1, tag) not in popped:\n",
        "                    queue.put((-(gamma[n, t]+self.transitions[t, tag]+emissions[n, tag] - log_z),(n+1, tag)))\n",
        "\n",
        "        best = torch.min(gamma[-1, :])\n",
        "\n",
        "        return best, log_z\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jiSwOqDZaln"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "quoz0jBNb26e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "ad85a382d17d4eaaaf3c2e41bf7b60a1",
            "251ac6ac2ee04fa6b1818de1574fd0aa",
            "e60aadf2942f488f92c835ff0f76afd9",
            "d5982f6c995c46bea208001fcf497fe0",
            "067b6b48aad8480da72116b3a0dba39f",
            "880b7b818e514b94acdc64ec79d30c72",
            "db3dd56b5d094e6fabf142552372bfcb",
            "e9cf330127aa484f91f6aee6bd9d3838",
            "bf5a348aa41b40da8f9b75407d1487dc",
            "815cf399dc29448a9ac2b49a6f2769a3",
            "fea0f5aacea44960b520d3afcbb5fcab"
          ]
        },
        "outputId": "7e50412c-1b21-4e09-ada7-fef21717831f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad85a382d17d4eaaaf3c2e41bf7b60a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "for i, data in enumerate(train_dataloader):\n",
        "    W_train = F.to_tensor(data[\"words\"], padding_value=pad_token_idx).to(DEVICE)\n",
        "    T_train = F.to_tensor(data[\"pos\"], padding_value=pos_vocab[pad_token]).to(DEVICE)\n",
        "    if i == 0:\n",
        "        break\n",
        "\n",
        "bert = BertModel.from_pretrained(TRANSFORMER).to(DEVICE)\n",
        "bert.eval()\n",
        "T_CAL = torch.tensor([i for i in range(pos_vocab.__len__())]).to(DEVICE)\n",
        "crf = NeuralCRF(\n",
        "    pad_idx_word=pad_token_idx,\n",
        "    pad_idx_pos=pos_vocab[pad_token],\n",
        "    bot_idx=pos_vocab[init_token],\n",
        "    t_cal=T_CAL,\n",
        "    transformer=bert,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bl-a_j9oemGI"
      },
      "source": [
        "## Q3a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_MqYdBcMeko3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35de816e-2fb2-45bf-a329-23518dd1ab4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PASSED\n"
          ]
        }
      ],
      "source": [
        "emissions = crf.calculate_emissions(W_train)\n",
        "for sentence in range(W_train.shape[0]):\n",
        "    for word_index in [1, 2, 3]:\n",
        "        assert torch.isclose(\n",
        "            crf.log_Z_naive(\n",
        "                W_train[sentence, :word_index],\n",
        "                emissions[\n",
        "                    sentence,\n",
        "                ],\n",
        "            ),\n",
        "            crf.backward_log_Z(W_train[:, :word_index], emissions)[sentence],\n",
        "            atol=1e-07\n",
        "        )\n",
        "        # print(crf.log_Z_naive(\n",
        "        #         W_train[sentence, :word_index],\n",
        "        #         emissions[\n",
        "        #             sentence,\n",
        "        #         ],))\n",
        "        # print(crf.backward_log_Z(W_train[:, :word_index], emissions)[sentence])\n",
        "print(\"PASSED\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jfi7hVAKNfRF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca048967-cc14-499e-95d1-2483035fe861"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PASSED\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "crf = NeuralCRF(\n",
        "    pad_idx_word=pad_token_idx,\n",
        "    pad_idx_pos=pos_vocab[pad_token],\n",
        "    bot_idx=pos_vocab[init_token],\n",
        "    t_cal=T_CAL,\n",
        "    transformer=bert,\n",
        ")\n",
        "emissions = crf.calculate_emissions(W_train)\n",
        "\n",
        "assert torch.all(torch.isclose(crf.backward_log_Z(W_train, emissions),\n",
        "    torch.tensor([ 87.7046677 ,  53.91382176,  51.06687669,  47.74253652,\n",
        "       108.39011677,  39.48809894,  38.95036134,  47.93318056,\n",
        "       105.83247378,  60.44181916,  57.37825015,  87.27584595,\n",
        "        56.36454825,  51.35881652,  81.8586711 ,  78.36976768,\n",
        "        80.75507746,  32.99132527,  60.26593105,  26.69618798,\n",
        "        44.96849009,  48.03838924,  51.79710605, 121.1404292 ,\n",
        "       148.84424765, 154.71288978,  39.11101607,  30.1374774 ,\n",
        "        26.99081028,  91.06613232,  60.98234626,  79.20111824], device='cuda:0',\n",
        "       dtype=torch.float64), atol=1e-07))\n",
        "\n",
        "#print(crf.backward_log_Z(W_train, emissions))\n",
        "print(\"PASSED\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdHg2VJUt5VY"
      },
      "source": [
        "## Q3b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "b9RkH9-4eqw2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f66feb86-5a12-4c74-9919-e8edfd37d14a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PASSED\n"
          ]
        }
      ],
      "source": [
        "emissions = crf.calculate_emissions(W_train)\n",
        "assert torch.all(\n",
        "    torch.isclose(\n",
        "        crf.backward_log_Z(W_train, emissions),\n",
        "        crf.forward_log_Z(W_train, emissions),\n",
        "        atol=1e-07\n",
        "    ),\n",
        "\n",
        ")\n",
        "# print(crf.backward_log_Z(W_train, emissions))\n",
        "# print(crf.forward_log_Z(W_train, emissions))\n",
        "print(\"PASSED\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoqeybSRvDyC"
      },
      "source": [
        "## Q3c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "HPHQf7ksetu8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eea9d46a-229c-4bce-8d62-12c7a758a6fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PASSED\n"
          ]
        }
      ],
      "source": [
        "emissions = crf.calculate_emissions(W_train)\n",
        "\n",
        "for sentence in range(W_train.shape[0]):\n",
        "    for word_index in [1, 2, 3]:\n",
        "        score_naive, sequence_naive = crf.viterbi_naive(\n",
        "            W_train[sentence, :word_index],\n",
        "            emissions[\n",
        "                sentence,\n",
        "            ],\n",
        "        )\n",
        "        # print(W_train[sentence, :word_index])\n",
        "        # print(W_train[sentence, :word_index].shape)\n",
        "        score_viterbi, backpointers_viterbi = crf.backward_viterbi_log(\n",
        "            W_train[sentence, :word_index],\n",
        "            emissions[\n",
        "                sentence,\n",
        "            ],\n",
        "        )\n",
        "        sequence_viterbi = crf.get_viterbi(backpointers_viterbi)\n",
        "        # print(score_viterbi[0,0])\n",
        "        # print(score_naive)\n",
        "        assert torch.isclose(score_viterbi[0, 0], score_naive, atol=1e-07)\n",
        "        assert torch.all(sequence_viterbi == sequence_naive)\n",
        "print(\"PASSED\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-4hs8vTzyLZD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0e0a955-4296-4c4b-ff1b-d70732e14f95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PASSED\n"
          ]
        }
      ],
      "source": [
        "# NB: Our evaluation expects Viterbi to only predict tags for actual\n",
        "# words, thus Viterbi (or get_viterbi) is supposed to remove instances\n",
        "# of PAD. Example: If Viterbi is asked to predict the sequence\n",
        "# [\"I\", \"like\" \"dogs\", \"PAD\", \"PAD\"], it should return a tagging\n",
        "# of length 3 (one for each valid word in the input).\n",
        "torch.manual_seed(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "crf = NeuralCRF(\n",
        "    pad_idx_word=pad_token_idx,\n",
        "    pad_idx_pos=pos_vocab[pad_token],\n",
        "    bot_idx=pos_vocab[init_token],\n",
        "    t_cal=T_CAL,\n",
        "    transformer=bert,\n",
        ")\n",
        "emissions = crf.calculate_emissions(W_train)\n",
        "sequences_overall = []\n",
        "first_batch_sequences_test =  [torch.tensor([10, 10, 10, 10, 10, 10, 10, 10, 15, 14, 10, 15, 14,  1,  3,  2,  4,  4,\n",
        "                                        4,  4,  4,  4, 14, 14,  4,  4,  4,  4, 15], device='cuda:0'),\n",
        "                                torch.tensor([14, 10, 10, 15, 15, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 15, 14],\n",
        "                                        device='cuda:0'),\n",
        "                                torch.tensor([14, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
        "                                        device='cuda:0'),\n",
        "                                torch.tensor([14, 13,  3, 13,  3,  3, 13,  4, 15, 15, 15, 15, 15,  6,  9, 10],\n",
        "                                        device='cuda:0'),\n",
        "                                torch.tensor([11, 10, 15, 10, 10, 10, 10, 10, 10, 10, 15, 10, 10,  3, 14, 14, 14, 13,\n",
        "                                        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 15,  6,  3,  2,  2, 18],\n",
        "                                        device='cuda:0'),\n",
        "                                torch.tensor([14,  9,  4, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'),\n",
        "                                torch.tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], device='cuda:0'),\n",
        "                                torch.tensor([14,  1, 10,  3, 14,  1,  3, 14,  8, 14, 14, 14, 14, 14,  0, 16],\n",
        "                                        device='cuda:0'),\n",
        "                                torch.tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
        "                                        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
        "                                        device='cuda:0'),\n",
        "                                torch.tensor([14, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
        "                                        10, 10], device='cuda:0'),\n",
        "                                torch.tensor([14, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
        "                                        2], device='cuda:0'),\n",
        "                                torch.tensor([ 9, 15, 15, 15, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
        "                                        10,  5, 14, 13, 14, 13,  4, 15,  2,  2,  2], device='cuda:0'),\n",
        "                                torch.tensor([14,  9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 14,  4, 14, 14,  0,\n",
        "                                        16], device='cuda:0'),\n",
        "                                torch.tensor([14, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
        "                                        device='cuda:0'),\n",
        "                                torch.tensor([14, 14, 14, 13,  3, 17, 10, 10, 15, 14, 14, 14, 14, 14, 14, 14, 14,  9,\n",
        "                                        10, 10, 10, 10, 10, 10, 10,  2,  2], device='cuda:0'),\n",
        "                                torch.tensor([14, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
        "                                        10, 10, 10, 10, 10, 10,  8, 14], device='cuda:0'),\n",
        "                                torch.tensor([14, 10, 10, 10, 10, 15, 10, 10, 15,  1, 10, 10, 10, 10, 10, 10, 10, 10,\n",
        "                                        10, 10, 10, 10, 15,  4, 14, 14, 14], device='cuda:0'),\n",
        "                                torch.tensor([14, 10, 10, 10, 10, 10, 10, 10, 10, 10, 15], device='cuda:0'),\n",
        "                                torch.tensor([14,  1, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
        "                                        10, 10], device='cuda:0'),\n",
        "                                torch.tensor([11, 10, 10, 10, 10, 10, 10, 10, 10], device='cuda:0'),\n",
        "                                torch.tensor([10, 10, 10, 10, 10, 10, 10, 10,  8, 14,  8, 14, 14, 14, 14],\n",
        "                                        device='cuda:0'),\n",
        "                                torch.tensor([14, 11, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
        "                                        device='cuda:0'),\n",
        "                                torch.tensor([ 9,  1,  9, 10, 10, 10, 15, 15, 10, 10, 10, 10, 10, 10,  6,  0,  6],\n",
        "                                        device='cuda:0'),\n",
        "                                torch.tensor([14, 10, 10, 15, 14, 15, 14, 14, 14, 15, 14, 11, 10, 10,  3, 14, 11, 10,\n",
        "                                        10, 15, 14, 14, 10, 10, 15, 14, 14, 10, 10, 10, 10, 10, 10, 15, 15, 15,\n",
        "                                        15, 15, 15, 14], device='cuda:0'),\n",
        "                                torch.tensor([10, 10, 10,  3, 14, 14,  9, 18, 14, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
        "                                        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
        "                                        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 15,  9], device='cuda:0'),\n",
        "                                torch.tensor([10, 10,  3, 10, 10, 10, 10, 10,  3,  2,  4,  4, 15,  3,  9, 10, 10, 10,\n",
        "                                        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,  0, 11, 10, 15,\n",
        "                                        6, 16, 10, 10, 10, 10, 15, 10, 10, 10, 10, 10, 10, 10, 10],\n",
        "                                        device='cuda:0'),\n",
        "                                torch.tensor([14, 14, 14, 14, 14, 14, 14, 11, 10, 10,  8, 17, 14], device='cuda:0'),\n",
        "                                torch.tensor([14,  3, 14, 11, 10,  3, 14, 11, 10, 15], device='cuda:0'),\n",
        "                                torch.tensor([14,  1, 14, 14, 14,  8,  3, 14, 14], device='cuda:0'),\n",
        "                                torch.tensor([15, 15, 10, 10, 10, 15,  1, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
        "                                        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 15], device='cuda:0'),\n",
        "                                torch.tensor([15, 15, 15, 15, 15,  3, 10, 10, 10, 15, 10, 10, 10,  3, 17,  4,  4, 15,\n",
        "                                        10, 15], device='cuda:0'),\n",
        "                                torch.tensor([10, 10, 10, 10, 10, 10, 15,  3, 14, 14, 10, 10, 10, 10, 15, 15, 14, 10,\n",
        "                                        10, 10, 10, 10, 10, 10, 10, 10], device='cuda:0')]\n",
        "\n",
        "for sentence in range(W_train.shape[0]):\n",
        "    score_viterbi, backpointers_viterbi = crf.backward_viterbi_log(\n",
        "        W_train[sentence, :],\n",
        "        emissions[\n",
        "            sentence,\n",
        "        ],\n",
        "    )\n",
        "    sequence_viterbi = crf.get_viterbi(backpointers_viterbi)\n",
        "    sequences_overall += [sequence_viterbi]\n",
        "\n",
        "assert torch.all(torch.tensor([torch.all(first_batch_sequences_test[ix].to(DEVICE) == sequences_overall[ix]) for ix in range(len(sequences_overall))]))\n",
        "\n",
        "print(\"PASSED\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwaRWIiVvLNQ"
      },
      "source": [
        "## Q3d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Yfch1WjMe1-u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a470f33-7711-4300-87a0-4bd2aecf4112"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PASSED\n"
          ]
        }
      ],
      "source": [
        "emissions = crf.calculate_emissions(W_train)\n",
        "\n",
        "for sentence in range(W_train.shape[0]):\n",
        "    for word_index in [1, 2, 3]:\n",
        "        score_viterbi, backpointers_viterbi = crf.backward_viterbi_log(\n",
        "            W_train[sentence, :word_index], emissions[sentence, :word_index]\n",
        "        )\n",
        "        score_dijkstra, log_Z = crf.dijkstra_viterbi_log(\n",
        "            W_train[sentence, :word_index], emissions[sentence, :word_index]\n",
        "        )\n",
        "\n",
        "        assert torch.isclose(\n",
        "            score_viterbi[0, 0],\n",
        "                score_dijkstra\n",
        "                + torch.sum(\n",
        "                    (W_train[sentence, :word_index] != crf.pad_idx_word)\n",
        "                )\n",
        "                * log_Z,\n",
        "                atol=1e-07\n",
        "        )\n",
        "\n",
        "print(\"PASSED\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RknzYtrUvln7"
      },
      "source": [
        "## Q3e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "49kT9v7yfO3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96caaf4a-e79b-4788-8ef6-c3ba25492102"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.07 ms ± 19.6 µs per loop (mean ± std. dev. of 2 runs, 5 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit -n 5 -r2\n",
        "score_viterbi, backpointers_viterbi = crf.backward_viterbi_log(W_train[0, :3], emissions[0, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-cHJ0nUdfhVo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0572e29-a2b1-4e04-d03d-29d2401b4c5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.62 s ± 62.9 ms per loop (mean ± std. dev. of 2 runs, 5 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit -n 5 -r2\n",
        "score_dijkstra, log_Z = crf.dijkstra_viterbi_log(W_train[0, :3], emissions[0, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "4P8rf_32vo-x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebd75bfa-73a6-4586-81dc-fb77d3c5008f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.64 s ± 10.9 ms per loop (mean ± std. dev. of 2 runs, 5 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit -n 5 -r2\n",
        "score_naive, sequence_naive = crf.viterbi_naive(W_train[0, :3], emissions[0, :])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfwKGTpTCRwd"
      },
      "source": [
        "It is possible to see that Dijkstra is slower, which is expected according to my calculations in Q2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zz5Gely7wU9X"
      },
      "source": [
        "## Q3f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ho8m3Vs-wVum"
      },
      "outputs": [],
      "source": [
        "def train_model_report_accuracy(\n",
        "    crf,\n",
        "    lr,\n",
        "    epochs,\n",
        "    train_dataloader,\n",
        "    dev_dataloader,\n",
        "    pad_token_idx_word,\n",
        "    pad_token_idx_tag,\n",
        "):\n",
        "\n",
        "    \"\"\"Train model for `epochs` epochs and report performance on\n",
        "        dev set after each epoch.\n",
        "\n",
        "    Parameters\n",
        "    ---\n",
        "    crf : NeuralCRF\n",
        "    lr : float\n",
        "        Learning rate to train with.\n",
        "    epochs : int\n",
        "        For how many epochs to train.\n",
        "    train_dataloader : torch.DataLoader\n",
        "    dev_dataloder : torch.DataLoader\n",
        "    pad_token_idx_word : int\n",
        "        Index with which to pad the word indices.\n",
        "    pad_token_idx_tag : int\n",
        "        Index with which to pad the tag indices.\n",
        "    \"\"\"\n",
        "    optimizer = torch.optim.Adam(crf.parameters(), lr=lr)\n",
        "    for epoch in range(epochs):\n",
        "        crf.train()\n",
        "        crf.transformer.train()\n",
        "        for i, data in enumerate(train_dataloader):\n",
        "            W = F.to_tensor(data[\"words\"], padding_value=pad_token_idx_word).to(DEVICE)\n",
        "            T = F.to_tensor(data[\"pos\"], padding_value=pad_token_idx_tag).to(DEVICE)\n",
        "            for param in crf.parameters():\n",
        "                param.grad = None\n",
        "            loss = crf.loss(T, W)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        crf.eval()\n",
        "        crf.transformer.eval()\n",
        "        with torch.no_grad():\n",
        "            predicted_sequences = []\n",
        "            true_sequences = []\n",
        "            for i_dev, data_dev in enumerate(valid_dataloader):\n",
        "                W_dev = F.to_tensor(\n",
        "                    data_dev[\"words\"], padding_value=pad_token_idx_word\n",
        "                ).to(DEVICE)\n",
        "                T_dev = F.to_tensor(\n",
        "                    data_dev[\"pos\"], padding_value=pad_token_idx_tag\n",
        "                ).to(DEVICE)\n",
        "                sequence_viterbi = crf(W_dev)\n",
        "                predicted_sequences += sequence_viterbi\n",
        "                for ix in range(W_dev.shape[0]):\n",
        "                    true_sequences += [\n",
        "                        T_dev[ix, : (sequence_viterbi[ix].shape[0])]\n",
        "                    ]\n",
        "            acc = torch.tensor(0.0).to(DEVICE)\n",
        "            for ix in range(len(predicted_sequences)):\n",
        "                acc += torch.mean(\n",
        "                    (predicted_sequences[ix] == true_sequences[ix]).float()\n",
        "                )\n",
        "            acc = acc / len(predicted_sequences)\n",
        "            print(\"-------------------------\")\n",
        "            print(f\"Epoch: {epoch + 1} / {epochs}\")\n",
        "            print(f\"Development set accuracy: {acc}\")\n",
        "            print(\"-------------------------\")\n",
        "        epoch += 1\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "TYrbXAELyRQR",
        "outputId": "cc213dfa-7c2e-456d-d017-16cd09bea5e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/datapipes/iter/combining.py:248: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
            "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------\n",
            "Epoch: 1 / 3\n",
            "Development set accuracy: 0.8552248477935791\n",
            "-------------------------\n",
            "-------------------------\n",
            "Epoch: 2 / 3\n",
            "Development set accuracy: 0.8941664099693298\n",
            "-------------------------\n",
            "-------------------------\n",
            "Epoch: 3 / 3\n",
            "Development set accuracy: 0.8996922373771667\n",
            "-------------------------\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "bert = BertModel.from_pretrained(TRANSFORMER).to(DEVICE)\n",
        "crf = NeuralCRF(\n",
        "    pad_idx_word=pad_token_idx,\n",
        "    pad_idx_pos=pos_vocab[pad_token],\n",
        "    bot_idx=pos_vocab[init_token],\n",
        "    t_cal=T_CAL,\n",
        "    transformer=bert,\n",
        ")\n",
        "\n",
        "train_model_report_accuracy(\n",
        "    crf,\n",
        "    LR,\n",
        "    EPOCHS,\n",
        "    train_dataloader,\n",
        "    valid_dataloader,\n",
        "    pad_token_idx,\n",
        "    pos_vocab[pad_token],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7j3Xr0HBxhq8"
      },
      "source": [
        "## Q3g)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "NgAws_iGxiX6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cf5f3c2-0b92-4e36-dfd3-205420163fe5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PASSED\n"
          ]
        }
      ],
      "source": [
        "emissions = crf.calculate_emissions(W_train)\n",
        "\n",
        "for sentence in range(W_train.shape[0]):\n",
        "    for word_index in [1, 2, 3]:\n",
        "        assert torch.isclose(\n",
        "            crf.entropy_naive(\n",
        "                W_train[sentence, :word_index],\n",
        "                emissions[\n",
        "                    sentence,\n",
        "                ],\n",
        "            ),\n",
        "            crf.backward_entropy(W_train[:, :word_index], emissions)[sentence],\n",
        "            atol=1e-04\n",
        "        )\n",
        "\n",
        "print(\"PASSED\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "XIgN1KTW8T9v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "31f8901b-7561-4176-be49-187bc8d9ce93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-73ed6199ca99>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[0memissions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_emissions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m assert torch.all(torch.isclose(crf.backward_entropy(W_train, emissions),\n\u001b[0m\u001b[1;32m     14\u001b[0m     torch.tensor([-2.69665035e+37,  2.23318055e+22, -1.43720747e+21, -3.77172095e+19,\n\u001b[1;32m     15\u001b[0m        \u001b[0;34m-\u001b[0m\u001b[0;36m1.47468585e+47\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m4.60982311e+15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m8.96114624e+15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2.66620540e+20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "torch.manual_seed(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "bert = BertModel.from_pretrained(TRANSFORMER).to(DEVICE)\n",
        "crf = NeuralCRF(\n",
        "    pad_idx_word=pad_token_idx,\n",
        "    pad_idx_pos=pos_vocab[pad_token],\n",
        "    bot_idx=pos_vocab[init_token],\n",
        "    t_cal=T_CAL,\n",
        "    transformer=bert,\n",
        ")\n",
        "emissions = crf.calculate_emissions(W_train)\n",
        "assert torch.all(torch.isclose(crf.backward_entropy(W_train, emissions),\n",
        "    torch.tensor([-2.69665035e+37,  2.23318055e+22, -1.43720747e+21, -3.77172095e+19,\n",
        "       -1.47468585e+47,  4.60982311e+15, -8.96114624e+15, -2.66620540e+20,\n",
        "       -6.01803307e+45,  5.64486026e+24, -1.41724632e+25, -6.25432556e+37,\n",
        "       -5.13592636e+23, -9.27744961e+21, -4.01553440e+35, -3.38492877e+33,\n",
        "       -1.01823554e+35,  1.75573266e+13, -5.52993136e+24, -6.16945452e+10,\n",
        "        1.83060232e+18,  7.18576385e+18, -1.06388015e+22, -3.28524515e+51,\n",
        "       -1.60395407e+64, -1.20556752e+67, -3.29681723e+16, -3.47751146e+12,\n",
        "       -8.19066087e+10, -1.66010499e+39, -1.45616448e+26, -2.05484106e+34], device='cuda:0', dtype=torch.float64), atol=1e-04, rtol=1e-04))\n",
        "print(\"PASSED\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "jgqBtmqXCRwe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78272bc5-7eb6-48ef-c296-806b7a5f5382"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-5.0866e+36,  7.5857e+22,  3.7726e+21,  1.8082e+20, -8.7506e+46,\n",
            "         3.2576e+16,  2.6980e+16,  1.1159e+20, -3.4804e+45,  2.6919e+25,\n",
            "        -6.3362e+24, -2.6027e+37,  1.3288e+24,  9.7487e+19, -2.1624e+35,\n",
            "        -1.8073e+32, -3.1403e+34,  9.4294e+13,  2.2471e+25,  2.4615e+11,\n",
            "         1.0133e+19,  1.9949e+20, -5.9377e+20, -7.4327e+50, -1.1123e+64,\n",
            "        -1.2056e+67,  2.5531e+16,  4.0210e+12,  2.4873e+11, -7.9774e+38,\n",
            "        -4.7528e+25, -1.1414e+34], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SumBackward1>)\n"
          ]
        }
      ],
      "source": [
        "# For some reason I am not passing the second test... My results are similar to the given ones but not inside the given tolerance, which probably means\n",
        "# I am doing something wrong... But my debugging was unsuccessful. However, the training process works pretty good achieving ~90% score.\n",
        "\n",
        "print(crf.backward_entropy(W_train, emissions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "jIKnm3b_Bm1N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9db64ee-5a0f-4a7e-d02d-fac31f314382"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------\n",
            "Epoch: 1 / 3\n",
            "Development set accuracy: 0.8732107281684875\n",
            "-------------------------\n",
            "-------------------------\n",
            "Epoch: 2 / 3\n",
            "Development set accuracy: 0.9064516425132751\n",
            "-------------------------\n",
            "-------------------------\n",
            "Epoch: 3 / 3\n",
            "Development set accuracy: 0.915988564491272\n",
            "-------------------------\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "bert = BertModel.from_pretrained(TRANSFORMER).to(DEVICE)\n",
        "entropy_regularized_crf = NeuralCRF(\n",
        "    pad_idx_word=pad_token_idx,\n",
        "    pad_idx_pos=pos_vocab[pad_token],\n",
        "    bot_idx=pos_vocab[init_token],\n",
        "    t_cal=T_CAL,\n",
        "    transformer=bert,\n",
        "    beta=10.0,\n",
        ")\n",
        "train_model_report_accuracy(\n",
        "    entropy_regularized_crf,\n",
        "    LR,\n",
        "    EPOCHS,\n",
        "    train_dataloader,\n",
        "    valid_dataloader,\n",
        "    pad_token_idx,\n",
        "    pos_vocab[pad_token],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "wdhhpDDfyj-8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3df7f5b8-628a-4965-937b-6e79333cec34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------\n",
            "Epoch: 1 / 3\n",
            "Development set accuracy: 0.873422384262085\n",
            "-------------------------\n",
            "-------------------------\n",
            "Epoch: 2 / 3\n",
            "Development set accuracy: 0.8988478183746338\n",
            "-------------------------\n",
            "-------------------------\n",
            "Epoch: 3 / 3\n",
            "Development set accuracy: 0.9121602773666382\n",
            "-------------------------\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "bert = BertModel.from_pretrained(TRANSFORMER).to(DEVICE)\n",
        "entropy_regularized_crf = NeuralCRF(\n",
        "    pad_idx_word=pad_token_idx,\n",
        "    pad_idx_pos=pos_vocab[pad_token],\n",
        "    bot_idx=pos_vocab[init_token],\n",
        "    t_cal=T_CAL,\n",
        "    transformer=bert,\n",
        "    beta=1.0,\n",
        ")\n",
        "train_model_report_accuracy(\n",
        "    entropy_regularized_crf,\n",
        "    LR,\n",
        "    EPOCHS,\n",
        "    train_dataloader,\n",
        "    valid_dataloader,\n",
        "    pad_token_idx,\n",
        "    pos_vocab[pad_token],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "DmCPsmTtym3U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34c25f1c-61db-4c8c-9df7-32838580184d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------\n",
            "Epoch: 1 / 3\n",
            "Development set accuracy: 0.8585146069526672\n",
            "-------------------------\n",
            "-------------------------\n",
            "Epoch: 2 / 3\n",
            "Development set accuracy: 0.8951640129089355\n",
            "-------------------------\n",
            "-------------------------\n",
            "Epoch: 3 / 3\n",
            "Development set accuracy: 0.9025139808654785\n",
            "-------------------------\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "bert = BertModel.from_pretrained(TRANSFORMER).to(DEVICE)\n",
        "entropy_regularized_crf = NeuralCRF(\n",
        "    pad_idx_word=pad_token_idx,\n",
        "    pad_idx_pos=pos_vocab[pad_token],\n",
        "    bot_idx=pos_vocab[init_token],\n",
        "    t_cal=T_CAL,\n",
        "    transformer=bert,\n",
        "    beta=0.1,\n",
        ")\n",
        "train_model_report_accuracy(\n",
        "    entropy_regularized_crf,\n",
        "    LR,\n",
        "    EPOCHS,\n",
        "    train_dataloader,\n",
        "    valid_dataloader,\n",
        "    pad_token_idx,\n",
        "    pos_vocab[pad_token],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adytD4tcEdOe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "498f457fbcc14886875fab4fcd871f59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1060efb83b8d476c8d9e72b7f9ee5827",
              "IPY_MODEL_6d2222cb877b4bf28ddee618c3eeac6d",
              "IPY_MODEL_148d87bc17934e8ba2b322ad4a3280b8"
            ],
            "layout": "IPY_MODEL_26598c6c02334282a02356f958672802"
          }
        },
        "1060efb83b8d476c8d9e72b7f9ee5827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_779010892eef4adba5c765ec22ae3384",
            "placeholder": "​",
            "style": "IPY_MODEL_10a706b2df004e259887993843ce3bad",
            "value": "vocab.txt: 100%"
          }
        },
        "6d2222cb877b4bf28ddee618c3eeac6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bbcc8c442b343edb59c3a16eb144b14",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca27d7d7815747fe8127e5568510c6a0",
            "value": 231508
          }
        },
        "148d87bc17934e8ba2b322ad4a3280b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f0d7278e9364215963e096127450f13",
            "placeholder": "​",
            "style": "IPY_MODEL_b8160921d3034fc8b9b30dffdbe38e37",
            "value": " 232k/232k [00:00&lt;00:00, 1.78MB/s]"
          }
        },
        "26598c6c02334282a02356f958672802": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "779010892eef4adba5c765ec22ae3384": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10a706b2df004e259887993843ce3bad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6bbcc8c442b343edb59c3a16eb144b14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca27d7d7815747fe8127e5568510c6a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f0d7278e9364215963e096127450f13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8160921d3034fc8b9b30dffdbe38e37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "febb608d89a5419bbc70774c234e2aae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e08f668f065483e84e52b1ea532aec6",
              "IPY_MODEL_5b1a46a3cc84494d83ca509e414028a9",
              "IPY_MODEL_4fb3fe063a6045a88a17727c6ff96ac1"
            ],
            "layout": "IPY_MODEL_ffc8a590e3e74589ba0c27c51fdc4343"
          }
        },
        "5e08f668f065483e84e52b1ea532aec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8df17a5aeb9d4eb9ac3144745f85106a",
            "placeholder": "​",
            "style": "IPY_MODEL_e82297e88da0405db434e7786864cd10",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "5b1a46a3cc84494d83ca509e414028a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a756d639d44d4c2ba12c093d3ee7b99f",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_738f7c9e49124a88a1d5febf1c84ed91",
            "value": 48
          }
        },
        "4fb3fe063a6045a88a17727c6ff96ac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e616948a07754177bf50292ac8282d45",
            "placeholder": "​",
            "style": "IPY_MODEL_121f62a69e694b11b109f0ce322f13d5",
            "value": " 48.0/48.0 [00:00&lt;00:00, 1.18kB/s]"
          }
        },
        "ffc8a590e3e74589ba0c27c51fdc4343": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8df17a5aeb9d4eb9ac3144745f85106a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e82297e88da0405db434e7786864cd10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a756d639d44d4c2ba12c093d3ee7b99f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "738f7c9e49124a88a1d5febf1c84ed91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e616948a07754177bf50292ac8282d45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "121f62a69e694b11b109f0ce322f13d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26a3355998a64550af04777458f8fdf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89ca8d90839244669e8aa735c7bff21a",
              "IPY_MODEL_d6b5166b421a449f862203a26811008c",
              "IPY_MODEL_fdc38209c0f9464295d2399f3b19248d"
            ],
            "layout": "IPY_MODEL_a854370ead25404bb74e4ce4975871c6"
          }
        },
        "89ca8d90839244669e8aa735c7bff21a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73c174c01a6d451e88e803fd447ece4b",
            "placeholder": "​",
            "style": "IPY_MODEL_8585a41acf78491493ed95c5363e35e9",
            "value": "config.json: 100%"
          }
        },
        "d6b5166b421a449f862203a26811008c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c6965d1559d4ef997d800a542fe98a8",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be6fe02046d046b1bebbc12f20f744e0",
            "value": 570
          }
        },
        "fdc38209c0f9464295d2399f3b19248d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_284a2cb092454bb2be87f530a1a2c5d2",
            "placeholder": "​",
            "style": "IPY_MODEL_aef28ee514ab4aaa811fd9155a06fa37",
            "value": " 570/570 [00:00&lt;00:00, 10.0kB/s]"
          }
        },
        "a854370ead25404bb74e4ce4975871c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73c174c01a6d451e88e803fd447ece4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8585a41acf78491493ed95c5363e35e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c6965d1559d4ef997d800a542fe98a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be6fe02046d046b1bebbc12f20f744e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "284a2cb092454bb2be87f530a1a2c5d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aef28ee514ab4aaa811fd9155a06fa37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad85a382d17d4eaaaf3c2e41bf7b60a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_251ac6ac2ee04fa6b1818de1574fd0aa",
              "IPY_MODEL_e60aadf2942f488f92c835ff0f76afd9",
              "IPY_MODEL_d5982f6c995c46bea208001fcf497fe0"
            ],
            "layout": "IPY_MODEL_067b6b48aad8480da72116b3a0dba39f"
          }
        },
        "251ac6ac2ee04fa6b1818de1574fd0aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_880b7b818e514b94acdc64ec79d30c72",
            "placeholder": "​",
            "style": "IPY_MODEL_db3dd56b5d094e6fabf142552372bfcb",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "e60aadf2942f488f92c835ff0f76afd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9cf330127aa484f91f6aee6bd9d3838",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf5a348aa41b40da8f9b75407d1487dc",
            "value": 440473133
          }
        },
        "d5982f6c995c46bea208001fcf497fe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_815cf399dc29448a9ac2b49a6f2769a3",
            "placeholder": "​",
            "style": "IPY_MODEL_fea0f5aacea44960b520d3afcbb5fcab",
            "value": " 440M/440M [00:06&lt;00:00, 50.2MB/s]"
          }
        },
        "067b6b48aad8480da72116b3a0dba39f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "880b7b818e514b94acdc64ec79d30c72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db3dd56b5d094e6fabf142552372bfcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9cf330127aa484f91f6aee6bd9d3838": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf5a348aa41b40da8f9b75407d1487dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "815cf399dc29448a9ac2b49a6f2769a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fea0f5aacea44960b520d3afcbb5fcab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}